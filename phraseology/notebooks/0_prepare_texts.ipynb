{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'language_tool_python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlanguage_tool_python\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'language_tool_python'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data of grammar mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../raw_data/train.csv')\n",
    "\n",
    "texts = data.loc[:, \"full_text\"].values\n",
    "scores = data.loc[:, \"phraseology\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear grammar errors - takes time\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "clear_texts = texts.copy()\n",
    "for i in range(texts.shape[0]):\n",
    "    clear_texts[i] = tool.correct(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavelpopov/.pyenv/versions/3.7.12/lib/python3.7/site-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# remove '.' and ',' symbols, cast to lowercase, split into words\n",
    "\n",
    "data = []\n",
    "for i in range(clear_texts.shape[0]):\n",
    "    # data.extend(np.array([clear_texts[i].replace('.', '').replace(',', '').lower().split()]))\n",
    "    data += [clear_texts[i].replace('.', '').replace(',', '').lower().split()]\n",
    "\n",
    "data = np.array(data) # data is numpy.ndarray of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean data\n",
    "np.savez(\n",
    "    \"../preprocessed_data/phraseology.npz\",\n",
    "    texts=texts,\n",
    "    clear_texts=clear_texts,\n",
    "    data=data,\n",
    "    scores=scores,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "np_data = np.load(\"../preprocessed_data/phraseology.npz\", allow_pickle=True)\n",
    "data = np_data['data']\n",
    "scores = np_data['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "np_data = np.load(\"../preprocessed_data/phraseology.npz\", allow_pickle=True)\n",
    "texts = np_data['clear_texts']\n",
    "scores = np_data['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)\n",
    "\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    texts, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    # padding='max_length',\n",
    "    pad_to_max_length=True, \n",
    "    max_length=512, \n",
    "    return_tensors='np'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "<class 'numpy.ndarray'>\n",
      "(3911,)\n",
      "(3911,)\n",
      "<class 'numpy.ndarray'>\n",
      "(3911,)\n",
      "<class 'numpy.ndarray'>\n",
      "(3911,)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data.keys())\n",
    "\n",
    "print(type(encoded_data[\"input_ids\"]))\n",
    "print(encoded_data[\"input_ids\"].shape)\n",
    "print(encoded_data[\"input_ids\"].shape)\n",
    "# print(encoded_data[\"input_ids\"][0])\n",
    "\n",
    "print(type(encoded_data[\"token_type_ids\"]))\n",
    "print(encoded_data[\"token_type_ids\"].shape)\n",
    "# print(encoded_data[\"token_type_ids\"][0])\n",
    "\n",
    "print(type(encoded_data[\"attention_mask\"]))\n",
    "print(encoded_data[\"attention_mask\"].shape)\n",
    "# print(encoded_data[\"attention_mask\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokenized data\n",
    "np.savez(\n",
    "    \"../preprocessed_data/tokenized.npz\",\n",
    "    input_ids=encoded_data[\"input_ids\"],\n",
    "    token_type_ids=encoded_data[\"token_type_ids\"],\n",
    "    attention_mask=encoded_data[\"attention_mask\"],\n",
    "    scores=scores,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('bert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90a31212d861d126ffb007c4fe25a6403a8c4a6d4a04b200190013599ca49d5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
