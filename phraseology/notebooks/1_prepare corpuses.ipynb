{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import mlconjug3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load idioms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load idioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/prateeksaxena2809/EPIE_Corpus - English idioms\n",
    "# I have cleaned them a little\n",
    "\n",
    "file = open('../raw_data/Formal_idioms.txt', 'r') # flexible idioms\n",
    "formal_idioms = file.readlines()\n",
    "file.close()\n",
    "\n",
    "file = open('../raw_data/Static_idioms.txt', 'r') # static idioms\n",
    "static_idioms = file.readlines()\n",
    "file.close()\n",
    "\n",
    "# split idiom strings into lists of idiom words\n",
    "for i in range(len(formal_idioms)):\n",
    "    formal_idioms[i] = formal_idioms[i].replace(\"\\n\", '').split(' ')\n",
    "for i in range(len(static_idioms)):\n",
    "    static_idioms[i] = static_idioms[i].replace(\"\\n\", '').split(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['get', 'to', '[pron]', 'point'], ['bring', '(somebody)', 'to', '([pron])', 'knees'], ['make', 'up', '[pron]', 'mind'], ['build', 'bridges'], ['raise', 'eyebrows']]\n",
      "\n",
      "[['just', 'in', 'case'], ['sorry', 'sight'], ['rule', 'of', 'thumb'], ['carpe', 'diem'], ['salad', 'days']]\n"
     ]
    }
   ],
   "source": [
    "print(formal_idioms[0:5])\n",
    "print()\n",
    "print(static_idioms[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate formal idioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare conjugates\n",
    "\n",
    "conjugator = mlconjug3.Conjugator(language=\"en\")\n",
    "\n",
    "conjugated_formal_idioms = []\n",
    "for idiom in formal_idioms:\n",
    "    conjugated_idiom = []\n",
    "\n",
    "    conjugated_verbs = []\n",
    "    raw_conjugated_verbs = conjugator.conjugate(idiom[0])\n",
    "    raw_conjugated_verbs = raw_conjugated_verbs.iterate()\n",
    "    for verb in raw_conjugated_verbs:\n",
    "        if \"to \" not in verb[-1] and \"/\" not in verb[-1]:\n",
    "            conjugated_verbs += [verb[-1]]\n",
    "    \n",
    "    # remove duplicates\n",
    "    conjugated_verbs = [*set(conjugated_verbs)]\n",
    "\n",
    "\n",
    "    for verb in conjugated_verbs:\n",
    "        raw_conjugated_idiom = [verb] + idiom[1:]\n",
    "        conjugated_idiom += [raw_conjugated_idiom]\n",
    "    \n",
    "    conjugated_formal_idioms += [conjugated_idiom]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['gets', 'to', '[pron]', 'point'], ['got', 'to', '[pron]', 'point'], ['getting', 'to', '[pron]', 'point'], ['gotten', 'to', '[pron]', 'point'], ['get', 'to', '[pron]', 'point']], [['brought', '(somebody)', 'to', '([pron])', 'knees'], ['bringing', '(somebody)', 'to', '([pron])', 'knees'], ['brings', '(somebody)', 'to', '([pron])', 'knees'], ['bring', '(somebody)', 'to', '([pron])', 'knees']], [['makes', 'up', '[pron]', 'mind'], ['made', 'up', '[pron]', 'mind'], ['make', 'up', '[pron]', 'mind'], ['making', 'up', '[pron]', 'mind']], [['build', 'bridges'], ['builds', 'bridges'], ['building', 'bridges'], ['built', 'bridges']], [['raising', 'eyebrows'], ['raise', 'eyebrows'], ['raises', 'eyebrows'], ['raised', 'eyebrows']]]\n"
     ]
    }
   ],
   "source": [
    "formal_idioms = conjugated_formal_idioms\n",
    "print(formal_idioms[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load phrasal verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load phrasal verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/WithEnglishWeCan/generated-english-phrasal-verbs\n",
    "# I've fixed it a little too\n",
    "file = open('../raw_data/phrasal_verbs_clean.json', 'r')\n",
    "raw_phrasal_verbs = json.load(file)\n",
    "keys = list(raw_phrasal_verbs.keys())\n",
    "\n",
    "phrasal_verbs = []\n",
    "for i in range(len(keys)):\n",
    "    # split phrasal verb\n",
    "    phrasal_verb = [keys[i].split(' ')]\n",
    "\n",
    "    phrasal_verbs += phrasal_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['abide', 'by'], ['accord', 'with'], ['account', 'for'], ['ache', 'for'], ['act', 'as']]\n"
     ]
    }
   ],
   "source": [
    "print(phrasal_verbs[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate phrasal verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare conjugates\n",
    "\n",
    "conjugator = mlconjug3.Conjugator(language=\"en\")\n",
    "\n",
    "conj_phrasal_verbs = []\n",
    "for phrasal_verb in phrasal_verbs:\n",
    "    conj_phrasal_verb = []\n",
    "\n",
    "    conj_verbs = []\n",
    "    raw_conj_verbs = conjugator.conjugate(phrasal_verb[0])\n",
    "    raw_conj_verbs = raw_conj_verbs.iterate()\n",
    "    for verb in raw_conj_verbs:\n",
    "        if \"to \" not in verb[-1] and \"/\" not in verb[-1]:\n",
    "            conj_verbs += [verb[-1]]\n",
    "    \n",
    "    # remove duplicates\n",
    "    conj_verbs = [*set(conj_verbs)]\n",
    "\n",
    "\n",
    "    for verb in conj_verbs:\n",
    "        raw_conj_phrasal_verb = [verb] + phrasal_verb[1:]\n",
    "        conj_phrasal_verb += [raw_conj_phrasal_verb]\n",
    "    \n",
    "    conj_phrasal_verbs += [conj_phrasal_verb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['abided', 'by'], ['abide', 'by'], ['abides', 'by'], ['abiding', 'by']], [['according', 'with'], ['accord', 'with'], ['accorded', 'with'], ['accords', 'with']], [['accounts', 'for'], ['accounting', 'for'], ['account', 'for'], ['accounted', 'for']], [['ache', 'for'], ['aches', 'for'], ['ached', 'for'], ['aching', 'for']], [['act', 'as'], ['acts', 'as'], ['acted', 'as'], ['acting', 'as']]]\n"
     ]
    }
   ],
   "source": [
    "phrasal_verbs = conj_phrasal_verbs\n",
    "print(phrasal_verbs[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save processed corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_idioms = np.array(formal_idioms)\n",
    "static_idioms = np.array(static_idioms)\n",
    "phrasal_verbs = np.array(phrasal_verbs)\n",
    "\n",
    "# save processed corpuses\n",
    "np.savez(\n",
    "    \"../preprocessed_data/corpuses.npz\",\n",
    "    formal_idioms=formal_idioms,\n",
    "    static_idioms=static_idioms,\n",
    "    phrasal_verbs=phrasal_verbs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpuses\n",
    "np_data = np.load(\"../preprocessed_data/corpuses.npz\", allow_pickle=True)\n",
    "\n",
    "formal_idioms = np_data['formal_idioms']\n",
    "static_idioms = np_data['static_idioms']\n",
    "phrasal_verbs = np_data['phrasal_verbs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([['gets', 'to', '[pron]', 'point'], ['got', 'to', '[pron]', 'point'], ['getting', 'to', '[pron]', 'point'], ['gotten', 'to', '[pron]', 'point'], ['get', 'to', '[pron]', 'point']])\n",
      " list([['brought', '(somebody)', 'to', '([pron])', 'knees'], ['bringing', '(somebody)', 'to', '([pron])', 'knees'], ['brings', '(somebody)', 'to', '([pron])', 'knees'], ['bring', '(somebody)', 'to', '([pron])', 'knees']])\n",
      " list([['makes', 'up', '[pron]', 'mind'], ['made', 'up', '[pron]', 'mind'], ['make', 'up', '[pron]', 'mind'], ['making', 'up', '[pron]', 'mind']])\n",
      " list([['build', 'bridges'], ['builds', 'bridges'], ['building', 'bridges'], ['built', 'bridges']])\n",
      " list([['raising', 'eyebrows'], ['raise', 'eyebrows'], ['raises', 'eyebrows'], ['raised', 'eyebrows']])]\n",
      "\n",
      "[list(['just', 'in', 'case']) list(['sorry', 'sight'])\n",
      " list(['rule', 'of', 'thumb']) list(['carpe', 'diem'])\n",
      " list(['salad', 'days'])]\n",
      "\n",
      "[list([['abided', 'by'], ['abide', 'by'], ['abides', 'by'], ['abiding', 'by']])\n",
      " list([['according', 'with'], ['accord', 'with'], ['accorded', 'with'], ['accords', 'with']])\n",
      " list([['accounts', 'for'], ['accounting', 'for'], ['account', 'for'], ['accounted', 'for']])\n",
      " list([['ache', 'for'], ['aches', 'for'], ['ached', 'for'], ['aching', 'for']])\n",
      " list([['act', 'as'], ['acts', 'as'], ['acted', 'as'], ['acting', 'as']])]\n"
     ]
    }
   ],
   "source": [
    "print(formal_idioms[0:5])\n",
    "print()\n",
    "print(static_idioms[0:5])\n",
    "print()\n",
    "print(phrasal_verbs[0:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('3.7.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b99d877adb0b7ab3fa56a43902a76f28d27732ee5cf08679707ced7dcdfd859"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
