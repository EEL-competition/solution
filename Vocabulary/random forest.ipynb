{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69730130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "717456d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from sklearn import mixture\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "834dfa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:\\\\Users\\\\mjafarlou1\\\\Desktop\\\\ELL\\\\train.csv')\n",
    "test = pd.read_csv('C:\\\\Users\\\\mjafarlou1\\\\Desktop\\\\ELL\\\\test.csv')\n",
    "submit = pd.read_csv('C:\\\\Users\\\\mjafarlou1\\\\Desktop\\\\ELL\\\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3991ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_text'] = train['full_text'].apply(lambda x: x.lower())\n",
    "test['full_text'] = test['full_text'].apply(lambda x: x.lower())\n",
    "\n",
    "story = []\n",
    "for doc in train['full_text']:\n",
    "    raw_sent = sent_tokenize(doc)\n",
    "    for sent in raw_sent:\n",
    "        story.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a574c4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5559269, 8109125)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    vector_size=200,\n",
    "    window=5,\n",
    "    min_count=2\n",
    ")\n",
    "\n",
    "model.build_vocab(story)\n",
    "\n",
    "model.train(story, total_examples=model.corpus_count, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb9e6791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10676"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78546986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc.split() if word in model.wv.index_to_key]\n",
    "    return np.mean(model.wv[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7de16e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3911/3911 [01:57<00:00, 33.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "X = []\n",
    "for doc in tqdm(train['full_text'].values):\n",
    "    w2v=document_vector(doc)\n",
    "    X.append(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0982477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 33.99it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "X1 = []\n",
    "for doc in tqdm(test['full_text'].values):\n",
    "    X1.append(document_vector(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2753c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X1 = np.array(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b5edba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 6/6 [10:50<00:00, 108.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: \t 0.18098597958111964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "      <td>3.255</td>\n",
       "      <td>3.060</td>\n",
       "      <td>3.065</td>\n",
       "      <td>3.010</td>\n",
       "      <td>2.570</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>do you think students would benefit from being...</td>\n",
       "      <td>3.185</td>\n",
       "      <td>2.805</td>\n",
       "      <td>2.985</td>\n",
       "      <td>2.895</td>\n",
       "      <td>2.915</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>thomas jefferson once states that \"it is wonde...</td>\n",
       "      <td>3.455</td>\n",
       "      <td>3.170</td>\n",
       "      <td>3.535</td>\n",
       "      <td>3.375</td>\n",
       "      <td>3.265</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0000C359D63E  when a person has no experience on a job their...     3.255   \n",
       "1  000BAD50D026  do you think students would benefit from being...     3.185   \n",
       "2  00367BB2546B  thomas jefferson once states that \"it is wonde...     3.455   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0   3.060       3.065        3.010    2.570         3.10  \n",
       "1   2.805       2.985        2.895    2.915         2.99  \n",
       "2   3.170       3.535        3.375    3.265         3.32  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = train.columns.to_list()[2::]\n",
    "metric1 = []\n",
    "\n",
    "for col in tqdm(columns):\n",
    "    \n",
    "    y = ((train[col]*2)-2).values\n",
    "    y = y.astype('int64')\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_resampled, y_resampled = RandomOverSampler().fit_resample(X, y)\n",
    "    \n",
    "    #X_train,X_test,y_train,y_test = train_test_split(X_resampled, y_resampled,test_size=0.2,random_state=1, stratify=y_resampled)\n",
    "    \n",
    "    dtree_model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "    dtree_model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    y_pred = dtree_model.predict(X_resampled)\n",
    "    \n",
    "    metric1.append(np.sqrt(mean_squared_error(y_resampled, y_pred)))\n",
    "    \n",
    "    test[col] = (np.clip((dtree_model.predict(X1)+2)/2, 1, 5)).astype('float64')\n",
    "    #print(grid.best_params_)\n",
    "                  \n",
    "print('metric:', '\\t', np.mean(metric1))    \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7cfa01b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>3.255</td>\n",
       "      <td>3.060</td>\n",
       "      <td>3.065</td>\n",
       "      <td>3.010</td>\n",
       "      <td>2.570</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>3.185</td>\n",
       "      <td>2.805</td>\n",
       "      <td>2.985</td>\n",
       "      <td>2.895</td>\n",
       "      <td>2.915</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.455</td>\n",
       "      <td>3.170</td>\n",
       "      <td>3.535</td>\n",
       "      <td>3.375</td>\n",
       "      <td>3.265</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion  syntax  vocabulary  phraseology  grammar  \\\n",
       "0  0000C359D63E     3.255   3.060       3.065        3.010    2.570   \n",
       "1  000BAD50D026     3.185   2.805       2.985        2.895    2.915   \n",
       "2  00367BB2546B     3.455   3.170       3.535        3.375    3.265   \n",
       "\n",
       "   conventions  \n",
       "0         3.10  \n",
       "1         2.99  \n",
       "2         3.32  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.drop(['full_text'], axis=1, inplace=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94e6054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45171875, -0.06575018, -0.0152784 , ..., -0.19296202,\n",
       "        -0.44129378, -0.3610303 ],\n",
       "       [-0.14648592,  0.08106826,  0.05594174, ..., -0.20188716,\n",
       "        -0.36851802, -0.45461655],\n",
       "       [-0.2573076 ,  0.12816374, -0.12199082, ..., -0.17975673,\n",
       "        -0.44584498, -0.18815804],\n",
       "       ...,\n",
       "       [-0.17771392, -0.03886845,  0.02306715, ..., -0.18903524,\n",
       "        -0.41661936, -0.3787562 ],\n",
       "       [-0.02274419, -0.03295993,  0.00403278, ..., -0.23277405,\n",
       "        -0.35421982, -0.42752478],\n",
       "       [-0.05372131,  0.17252055,  0.02505984, ..., -0.18969907,\n",
       "        -0.5608798 , -0.52511215]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6aefe42d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y must have at least two dimensions for multi-output regression but has only one.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVR\n\u001b[0;32m      5\u001b[0m chain \u001b[38;5;241m=\u001b[39m MultiOutputRegressor(SVR())\n\u001b[1;32m----> 6\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(chain\u001b[38;5;241m.\u001b[39mscore(X,y))\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\jupyter_gpt\\lib\\site-packages\\sklearn\\multioutput.py:190\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    187\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my must have at least two dimensions for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti-output regression but has only one.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m     )\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_fit_parameter(\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m ):\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: y must have at least two dimensions for multi-output regression but has only one."
     ]
    }
   ],
   "source": [
    "############################\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "chain = MultiOutputRegressor(SVR())\n",
    "chain.fit(X, y)\n",
    "print(chain.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf59d6e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_tfIdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_test_tfIdf\u001b[49m)\n\u001b[0;32m      2\u001b[0m submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocabulary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions[:,\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      3\u001b[0m submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocabulary\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_tfIdf' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = chain.predict(X_test_tfIdf)\n",
    "submission['vocabulary'] = predictions[:,2]\n",
    "submission['vocabulary'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0b9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1429a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
